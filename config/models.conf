# SAM Model Configuration
# This file is created automatically by setup_models.py

[embedding_model]
name = "all-MiniLM-L6-v2"
provider = "sentence-transformers"
cache_dir = "models/embeddings"

[llm_model]
provider = "ollama"
api_url = "http://localhost:11434"
default_model = "hf.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF:Q4_K_M"
fallback_models = ["qwen2.5:7b", "qwen2.5:3b", "llama3.2:3b", "phi3:mini"]

[model_settings]
max_context_length = 4096
temperature = 0.7
max_tokens = 1000
timeout_seconds = 60
