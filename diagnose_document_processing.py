#!/usr/bin/env python3
"""
SAM Document Processing Diagnostic Script
Identifies why SAM cannot read uploaded documents.
"""

import os
import sys
import logging
from pathlib import Path
import tempfile

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def check_file_system():
    """Check file system and directory structure."""
    print("üîç STEP 1: File System Check")
    print("=" * 50)
    
    current_dir = os.getcwd()
    print(f"üìÅ Current directory: {current_dir}")
    
    # Check for key directories
    directories_to_check = [
        "memory_store",
        "chroma_db",
        "data/uploads", 
        "multimodal_processing",
        "memory",
        "logs"
    ]
    
    for directory in directories_to_check:
        exists = os.path.exists(directory)
        status = "‚úÖ EXISTS" if exists else "‚ùå MISSING"
        print(f"üìÇ {directory}: {status}")
        
        if exists and os.path.isdir(directory):
            try:
                files = os.listdir(directory)
                file_count = len(files)
                print(f"   üìÑ Contains {file_count} files/folders")
                if file_count > 0 and file_count <= 5:
                    print(f"   üìã Contents: {files}")
            except PermissionError:
                print("   ‚ö†Ô∏è  Permission denied")
    
    # Check for ChromaDB files specifically
    print("\nüîç ChromaDB Files Search:")
    for root, dirs, files in os.walk("."):
        for file in files:
            if "chroma" in file.lower() or file.endswith(".sqlite3"):
                print(f"   üìÑ {os.path.join(root, file)}")
    
    print()

def check_multimodal_pipeline():
    """Check if multimodal pipeline can be imported and initialized."""
    print("üîç STEP 2: Multimodal Pipeline Check")
    print("=" * 50)
    
    try:
        from multimodal_processing.multimodal_pipeline import get_multimodal_pipeline
        print("‚úÖ Multimodal pipeline import successful")
        
        try:
            pipeline = get_multimodal_pipeline()
            print("‚úÖ Multimodal pipeline initialization successful")
            print(f"   üìä Pipeline type: {type(pipeline)}")
            
            # Check if pipeline has required methods
            required_methods = ['process_document', 'process_documents_batch']
            for method in required_methods:
                if hasattr(pipeline, method):
                    print(f"   ‚úÖ Method '{method}' available")
                else:
                    print(f"   ‚ùå Method '{method}' MISSING")
            
            return pipeline
            
        except Exception as e:
            print(f"‚ùå Multimodal pipeline initialization failed: {e}")
            return None
            
    except ImportError as e:
        print(f"‚ùå Multimodal pipeline import failed: {e}")
        return None
    except Exception as e:
        print(f"‚ùå Unexpected error: {e}")
        return None

def check_memory_stores():
    """Check memory store initialization and status."""
    print("üîç STEP 3: Memory Store Check")
    print("=" * 50)
    
    # Check regular memory store
    try:
        from memory.memory_vectorstore import get_memory_store, VectorStoreType
        print("‚úÖ Regular memory store import successful")
        
        try:
            memory_store = get_memory_store(
                store_type=VectorStoreType.CHROMA,
                storage_directory="memory_store",
                embedding_dimension=384
            )
            print("‚úÖ Regular memory store initialization successful")
            
            # Check if store has documents
            try:
                # Try to search for any documents
                results = memory_store.search_memories(
                    query="",
                    memory_type="document",
                    max_results=10
                )
                print(f"   üìÑ Found {len(results)} documents in regular store")
                
                if results:
                    for i, result in enumerate(results[:3]):
                        filename = "Unknown"
                        if hasattr(result, 'metadata') and result.metadata:
                            filename = result.metadata.get('filename', 'Unknown')
                        elif hasattr(result, 'chunk') and hasattr(result.chunk, 'source'):
                            filename = result.chunk.source
                        print(f"   üìã Document {i+1}: {filename}")
                        
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Could not search documents: {e}")
                
        except Exception as e:
            print(f"‚ùå Regular memory store initialization failed: {e}")
            
    except ImportError as e:
        print(f"‚ùå Regular memory store import failed: {e}")
    
    print()
    
    # Check secure memory store
    try:
        from memory.secure_memory_vectorstore import get_secure_memory_store, VectorStoreType
        print("‚úÖ Secure memory store import successful")
        
        try:
            secure_store = get_secure_memory_store(
                store_type=VectorStoreType.CHROMA,
                storage_directory="memory_store",
                embedding_dimension=384,
                enable_encryption=False  # Disable encryption for testing
            )
            print("‚úÖ Secure memory store initialization successful")
            
            # Check security status
            try:
                status = secure_store.get_security_status()
                print(f"   üîê Security status: {status}")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Could not get security status: {e}")
                
        except Exception as e:
            print(f"‚ùå Secure memory store initialization failed: {e}")
            
    except ImportError as e:
        print(f"‚ùå Secure memory store import failed: {e}")

def test_document_processing(pipeline):
    """Test document processing with a sample file."""
    print("üîç STEP 4: Document Processing Test")
    print("=" * 50)
    
    if not pipeline:
        print("‚ùå Cannot test - multimodal pipeline not available")
        return
    
    # Create a test document
    test_content = """
    Test Document for SAM Diagnostic
    
    This is a test document to verify that SAM's document processing pipeline is working correctly.
    
    Key Information:
    - Document type: Test file
    - Purpose: Diagnostic testing
    - Content: Sample text for processing
    
    If you can read this in SAM's responses, the document processing is working!
    """
    
    try:
        # Create temporary test file
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as temp_file:
            temp_file.write(test_content)
            temp_file_path = temp_file.name
        
        print(f"üìÑ Created test file: {temp_file_path}")
        
        # Test multimodal pipeline processing
        try:
            print("üîÑ Testing multimodal pipeline processing...")
            result = pipeline.process_document(temp_file_path)
            
            if result:
                print("‚úÖ Multimodal pipeline processing successful!")
                print(f"   üìä Result type: {type(result)}")
                print(f"   üìã Result keys: {list(result.keys()) if isinstance(result, dict) else 'Not a dict'}")
                
                if isinstance(result, dict):
                    for key, value in result.items():
                        if isinstance(value, (str, int, float, bool)):
                            print(f"   üìù {key}: {value}")
                        else:
                            print(f"   üìù {key}: {type(value)} (length: {len(value) if hasattr(value, '__len__') else 'N/A'})")
            else:
                print("‚ùå Multimodal pipeline returned None/empty result")
                
        except Exception as e:
            print(f"‚ùå Multimodal pipeline processing failed: {e}")
            import traceback
            print(f"   üîç Traceback: {traceback.format_exc()}")
        
        # Test memory store addition
        try:
            print("\nüîÑ Testing memory store addition...")
            from memory.memory_vectorstore import get_memory_store, VectorStoreType
            
            memory_store = get_memory_store(
                store_type=VectorStoreType.CHROMA,
                storage_directory="memory_store",
                embedding_dimension=384
            )
            
            # Add test document to memory store
            chunk_id = memory_store.add_memory(
                content=f"Test Document: diagnostic_test.txt\n\n{test_content}",
                source="diagnostic_test",
                tags=['test', 'diagnostic'],
                importance_score=0.8,
                metadata={
                    'filename': 'diagnostic_test.txt',
                    'test_document': True,
                    'diagnostic_timestamp': str(os.path.getmtime(temp_file_path))
                }
            )
            
            print(f"‚úÖ Successfully added to memory store with ID: {chunk_id}")
            
            # Test retrieval
            search_results = memory_store.search_memories(
                query="diagnostic test document",
                max_results=5
            )
            
            print(f"   üîç Search found {len(search_results)} results")
            for i, result in enumerate(search_results):
                if hasattr(result, 'chunk') and hasattr(result.chunk, 'content'):
                    content_preview = result.chunk.content[:100] + "..." if len(result.chunk.content) > 100 else result.chunk.content
                    print(f"   üìÑ Result {i+1}: {content_preview}")
                    
        except Exception as e:
            print(f"‚ùå Memory store test failed: {e}")
            import traceback
            print(f"   üîç Traceback: {traceback.format_exc()}")
        
        # Cleanup
        try:
            os.unlink(temp_file_path)
            print(f"üßπ Cleaned up test file: {temp_file_path}")
        except Exception as e:
            print(f"‚ö†Ô∏è  Could not clean up test file: {e}")
            
    except Exception as e:
        print(f"‚ùå Test document creation failed: {e}")

def check_dependencies():
    """Check required dependencies."""
    print("üîç STEP 5: Dependencies Check")
    print("=" * 50)
    
    required_packages = [
        'chromadb',
        'sentence_transformers', 
        'PyPDF2',
        'streamlit'
    ]
    
    for package in required_packages:
        try:
            __import__(package)
            print(f"‚úÖ {package}: Available")
        except ImportError:
            print(f"‚ùå {package}: MISSING")
    
    # Check specific components
    components_to_check = [
        ('memory.memory_vectorstore', 'MemoryVectorStore'),
        ('multimodal_processing.multimodal_pipeline', 'MultimodalProcessingPipeline'),
        ('multimodal_processing.document_parser', 'DocumentParser'),
        ('multimodal_processing.knowledge_consolidator', 'KnowledgeConsolidator')
    ]
    
    print("\nüîç SAM Components Check:")
    for module_name, component_name in components_to_check:
        try:
            module = __import__(module_name, fromlist=[component_name])
            if hasattr(module, component_name):
                print(f"‚úÖ {module_name}.{component_name}: Available")
            else:
                print(f"‚ö†Ô∏è  {module_name}: Module exists but {component_name} not found")
        except ImportError as e:
            print(f"‚ùå {module_name}: Import failed - {e}")

def main():
    """Run complete diagnostic."""
    print("üîß SAM Document Processing Diagnostic")
    print("=" * 60)
    print("This script will identify why SAM cannot read uploaded documents.\n")
    
    # Run all diagnostic steps
    check_file_system()
    pipeline = check_multimodal_pipeline()
    check_memory_stores()
    test_document_processing(pipeline)
    check_dependencies()
    
    print("\n" + "=" * 60)
    print("üéØ DIAGNOSTIC COMPLETE")
    print("=" * 60)
    print("\nüìã Next Steps:")
    print("1. Review the output above for any ‚ùå FAILED items")
    print("2. If multimodal pipeline failed, check multimodal_processing/ directory")
    print("3. If memory stores failed, check ChromaDB installation")
    print("4. If test processing failed, check the specific error messages")
    print("5. Run this script again after fixing any issues")
    print("\nüí° If you see ‚úÖ SUCCESS for all steps but still can't read documents,")
    print("   the issue might be in the Streamlit app initialization or security.")

if __name__ == "__main__":
    main()
